{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19005999",
   "metadata": {},
   "source": [
    "## Said Saterih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63fa853b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8176e8f6",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2d7f0",
   "metadata": {},
   "source": [
    "## Numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33cd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.genfromtxt(\"./Xtr0_mat100.csv\", delimiter=\" \")\n",
    "y0 = np.genfromtxt(\"./Ytr0.csv\", delimiter = \",\",  skip_header = 1, usecols = 1)\n",
    "Xte0 = np.genfromtxt(\"./Xte0_mat100.csv\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866288c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.genfromtxt(\"./Xtr1_mat100.csv\", delimiter=\" \")\n",
    "y1 = np.genfromtxt(\"./Ytr1.csv\", delimiter = \",\",  skip_header = 1, usecols = 1)\n",
    "Xte1 = np.genfromtxt(\"./Xte1_mat100.csv\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2835304",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.genfromtxt(\"./Xtr2_mat100.csv\", delimiter=\" \")\n",
    "y2 = np.genfromtxt(\"./Ytr2.csv\", delimiter = \",\",  skip_header = 1, usecols = 1)\n",
    "Xte2 = np.genfromtxt(\"./Xte2_mat100.csv\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b19536",
   "metadata": {},
   "source": [
    "## DNA Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf83de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"./Xtr0.csv\")\n",
    "X.set_index('Id', inplace=True)\n",
    "y = pd.read_csv(\"./Ytr0.csv\")\n",
    "y.set_index('Id', inplace=True)\n",
    "Xte =  pd.read_csv(\"./Xte0.csv\")\n",
    "Xte.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a58e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.read_csv(\"./Xtr1.csv\")\n",
    "X3.set_index('Id', inplace=True)\n",
    "y3 = pd.read_csv(\"./Ytr1.csv\")\n",
    "y3.set_index('Id', inplace=True)\n",
    "Xte3 =  pd.read_csv(\"./Xte1.csv\")\n",
    "Xte3.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad80159",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = pd.read_csv(\"./Xtr2.csv\")\n",
    "X4.set_index('Id', inplace=True)\n",
    "y4 = pd.read_csv(\"./Ytr2.csv\")\n",
    "y4.set_index('Id', inplace=True)\n",
    "Xte4 =  pd.read_csv(\"./Xte2.csv\")\n",
    "Xte4.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5122f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kernel matrices : polynomial ,  RBF, Spectrum\n",
    "class kernels :\n",
    "    def __init__(self, Xtrain):\n",
    "        self.Xtr = Xtrain\n",
    "        \n",
    "    def linear_kernel(self, X):\n",
    "        \"\"\"\n",
    "        \n",
    "        Implement the linear kernel\n",
    "        \n",
    "        \"\"\"\n",
    "        return np.dot(X, self.Xtr.T)\n",
    "    \n",
    "    def polynomial_kernel(self, X,s):\n",
    "        \"\"\"\n",
    "        \n",
    "        Implement polynomial kernel \n",
    "        \n",
    "        \"\"\"\n",
    "        return (np.dot(X, self.Xtr.T))**s\n",
    "        \n",
    "    def gaussian_kernel(self, X):\n",
    "        \"\"\"\n",
    "        \n",
    "        Implement gaussian kernel\n",
    "        \n",
    "        \"\"\"\n",
    "        # Bandwidth\n",
    "        n = self.Xtr.shape[0]\n",
    "        sigma2 = (1/n**(2/5)) * np.sqrt(np.trace(np.cov(self.Xtr, rowvar = False)))\n",
    "        \n",
    "        # Compute the pairwise distances\n",
    "        D = np.sum((X[:, np.newaxis] - self.Xtr[np.newaxis, :])**2, axis=2)\n",
    "\n",
    "        # Compute the RBF kernel matrix\n",
    "        kernel_matrix = np.exp(-D / (2 * self.sigma**2))\n",
    "     \n",
    "    ## Implement the spectrum kernel\n",
    "    def spectrum_kernel1(self,sequence1, sequence2, k):\n",
    "        \"\"\"\n",
    "        Implement the spectrum kernel\n",
    "        \"\"\"\n",
    "        kmer_counts1 = Counter(sequence1[i:i+k] for i in range(len(sequence1) - k + 1))\n",
    "        kmer_counts2 = Counter(sequence2[i:i+k] for i in range(len(sequence2) - k + 1))\n",
    "        \n",
    "        common_kmers = list(set(kmer_counts1.keys()) & set(kmer_counts2.keys()))\n",
    "        \n",
    "        res = 0\n",
    "        for kmer in common_kmers:\n",
    "            res = res + kmer_counts1[kmer] * kmer_counts2[kmer] \n",
    "            \n",
    "        return res\n",
    "        \n",
    "    def spectrum_kernel2(self,X,k):\n",
    "        \"\"\"\n",
    "        Assemble the kernel matrix given by spectrum method\n",
    "        \"\"\"\n",
    "        n = self.Xtr.shape[0]\n",
    "        K = np.zeros((X.shape[0], n))\n",
    "        \n",
    "        if (K.shape[0] == K.shape[1]):\n",
    "            rows, cols = np.tril_indices(n, -1)\n",
    "        else : \n",
    "            rows, cols = np.indices((K.shape[0],K.shape[1]))\n",
    "            rows = rows.reshape(-1)\n",
    "            cols = cols.reshape(-1)\n",
    "        \n",
    "        values = Parallel(n_jobs=8)(\n",
    "            delayed(self.spectrum_kernel1)(X.iloc[i][\"seq\"], self.Xtr.iloc[j][\"seq\"], k) for i, j in zip(rows, cols)\n",
    "        )\n",
    "\n",
    "        K[rows, cols] = values\n",
    "        \n",
    "        if (K.shape[0] == K.shape[1]):\n",
    "            \n",
    "            K += K.T\n",
    "        \n",
    "            diag_values = Parallel(n_jobs=8)(\n",
    "                delayed(self.spectrum_kernel1)(X.iloc[i][\"seq\"], self.Xtr.iloc[i][\"seq\"], k) for i in range(n)\n",
    "            )\n",
    "            K[np.diag_indices(n)] = diag_values\n",
    "\n",
    "        return K\n",
    "    \n",
    "    \n",
    "## Training algorithms\n",
    "\n",
    "class training_algo:\n",
    "    \n",
    "    def __init__(self, kernel , label ):\n",
    "        self.n = kernel.shape[0] # size training set\n",
    "        self.K = kernel # kernel matrix\n",
    "        self.y = label # training label\n",
    "    \n",
    "    # Logistic regression\n",
    "    def obj_fun_log(self, alpha, lbda):\n",
    "        \"\"\"\n",
    "        Objective function for kernel logistic regression.\n",
    "\n",
    "        Parameters:\n",
    "        alpha (numpy.ndarray): Coefficient vector.\n",
    "        lbda (float): Regularization parameter.\n",
    "\n",
    "        Returns:\n",
    "        float: Value of the objective function.\n",
    "        \"\"\"\n",
    "        \n",
    "        Ka = self.K @ alpha\n",
    "        data_fit = -np.mean(np.log(expit(self.y * Ka) + 1e-10))\n",
    "        reg = lbda * alpha.T.dot(Ka) / 2\n",
    "        return data_fit + reg\n",
    "    \n",
    "    # SVM (Primal form)\n",
    "    def SVM(self, alpha, lbda):\n",
    "        \"\"\"\n",
    "        Objective function for kernel SVM.\n",
    "\n",
    "        Parameters:\n",
    "        alpha (numpy.ndarray): Coefficient vector.\n",
    "        lbda (float): Regularization parameter.\n",
    "\n",
    "        Returns:\n",
    "        float: Value of the objective function.\n",
    "        \"\"\"\n",
    "        \n",
    "        Ka = self.K.dot(alpha)  # Compute the kernel product\n",
    "        \n",
    "        # Compute element-wise hinge loss\n",
    "        hinge_loss = np.mean(np.maximum(0, 1 - self.y * Ka))\n",
    "\n",
    "        # Regularization term\n",
    "        reg = lbda * alpha.T.dot(Ka) / 2\n",
    "\n",
    "        return hinge_loss + reg\n",
    "    \n",
    "    def SVM2(self, alpha, lbda):\n",
    "        \"\"\"\n",
    "        Objective function for SVM2.\n",
    "\n",
    "        Parameters:\n",
    "        alpha (numpy.ndarray): Coefficient vector.\n",
    "        lbda (float): Regularization parameter.\n",
    "\n",
    "        Returns:\n",
    "        float: Value of the objective function.\n",
    "        \"\"\"\n",
    "        \n",
    "        Ka = self.K.dot(alpha)  # Compute the kernel product\n",
    "        \n",
    "        # Compute element-wise hinge loss\n",
    "        hinge_loss = np.mean(np.maximum(0, 1 - self.y * Ka)**2)\n",
    "\n",
    "        # Regularization term\n",
    "        reg = lbda * alpha.T.dot(Ka) / 2\n",
    "\n",
    "        return hinge_loss + reg\n",
    "    \n",
    "    \n",
    "    def minimize_obj_fun(self,pb, alpha0):\n",
    "        \"\"\"\n",
    "        Minimize the objective function using L-BFGS-B.\n",
    "\n",
    "        Parameters:\n",
    "        pb (function): Objective function to minimize.\n",
    "        alpha0 (numpy.ndarray): Initial coefficient vector.\n",
    "        lbda (float): Regularization parameter.\n",
    "\n",
    "        Returns:\n",
    "        scipy.optimize.OptimizeResult: Result of the optimization.\n",
    "        \"\"\"\n",
    "        lbda = np.sqrt(1/self.n)\n",
    "        result = minimize(\n",
    "            fun=pb,\n",
    "            x0=alpha0,\n",
    "            args=(lbda,),\n",
    "            method='L-BFGS-B',\n",
    "            options={'disp': True}\n",
    "        )\n",
    "        return result  \n",
    "\n",
    "## Prediction\n",
    "\n",
    "class prediction:\n",
    "    def __init__(self, coeff,  Xtest, ker):\n",
    "        self.alpha = coeff # Coefficient learned\n",
    "        self.Xte = Xtest # testing set\n",
    "        self.kernel = ker # kernel\n",
    "        \n",
    "    def linear_prediction(self):\n",
    "        K_test = self.kernel.linear_kernel(self.Xte)\n",
    "        f = K_test.dot(self.alpha)\n",
    "        return (np.sign(f) + 1.) / 2\n",
    "    \n",
    "    def polynomial_prediction(self,s):\n",
    "        K_test = self.kernel.polynomial_kernel(self.Xte,s)\n",
    "        f = K_test.dot(self.alpha)\n",
    "        return (np.sign(f) + 1.) / 2\n",
    "    \n",
    "    def spectrum_prediction(self,k):\n",
    "        K_test = self.kernel.spectrum_kernel2(self.Xte, k)\n",
    "        f = K_test.dot(self.alpha)\n",
    "        return (np.where(f >= 0, 1, -1) + 1) / 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5e6aa",
   "metadata": {},
   "source": [
    "# Prediction for spectrum kernel using logistic classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4119877",
   "metadata": {},
   "source": [
    "# Prediction with spectrum kernel with k = 5 using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ec8eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First dataset\n",
    "\n",
    "ker= kernels(X)\n",
    "Kspec = ker.spectrum_kernel2(X,k=5)\n",
    "Kspec = Kspec + 10**(-10) * np.eye(X.shape[0])\n",
    "train = training_algo(Kspec, 2*(y['Bound'].to_numpy(float) - 0.5))\n",
    "alpha = train.minimize_obj_fun(train.obj_fun_log, np.zeros(Kspec.shape[0]))\n",
    "pred = prediction(alpha.x, Xte, ker)\n",
    "Yte = pred.spectrum_prediction(5)\n",
    "\n",
    "## Second dataset\n",
    "\n",
    "ker3= kernels(X3)\n",
    "Kspec3 = ker3.spectrum_kernel2(X3,k=5)\n",
    "Kspec3 = Kspec3 + 10**(-10) * np.eye(X3.shape[0])\n",
    "train3 = training_algo(Kspec3, 2*(y3['Bound'].to_numpy(float) - 0.5))\n",
    "alpha3 = train.minimize_obj_fun(train3.obj_fun_log, np.zeros(Kspec3.shape[0]))\n",
    "pred3 = prediction(alpha3.x, Xte3, ker3)\n",
    "Yte3 = pred3.spectrum_prediction(5)\n",
    "\n",
    "\n",
    "## Third dataset\n",
    "\n",
    "\n",
    "ker4= kernels(X4)\n",
    "Kspec4 = ker4.spectrum_kernel2(X4,k=5) + 10**(-10)*np.eye(X4.shape[0])\n",
    "train4 = training_algo(Kspec4, 2*(y4['Bound'].to_numpy(float) - 0.5))\n",
    "alpha4 = train.minimize_obj_fun(train4.obj_fun_log ,np.zeros(Kspec4.shape[0]))\n",
    "pred4 = prediction(alpha4.x, Xte4, ker4)\n",
    "Yte4 = pred4.spectrum_prediction(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe7e61",
   "metadata": {},
   "source": [
    "## Create a CSV for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4642373",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_concatenee = []\n",
    "liste_concatenee.extend(Yte)\n",
    "liste_concatenee.extend(Yte3)\n",
    "liste_concatenee.extend(Yte4)\n",
    "                    \n",
    "# Créer un DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Id': [int(x) for x in list(range(3000))],\n",
    "    'Bound': [int(x) for x in liste_concatenee] \n",
    "})\n",
    "df['Bound'] = df['Bound'].astype('int')\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "df.to_csv('Ypred_spec.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b3153",
   "metadata": {},
   "source": [
    "## Cross validation for polynomial kernel (on the degrees) and learn on the best hyperparameters using SVM (primal form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b4824d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, s_values, n_splits=5):\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "\n",
    "    for s in s_values:\n",
    "        scores = []\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            ker = kernels(X_train)\n",
    "            K = ker.polynomial_kernel(X_train, s=s)\n",
    "            K = K + 10**(-10) * np.eye(X_train.shape[0])\n",
    "\n",
    "            train = training_algo(K, 2*(y_train - 0.5))\n",
    "            alpha = train.minimize_obj_fun(train.SVM, np.ones(K.shape[0]))\n",
    "\n",
    "            pred = prediction(alpha.x, X_val, ker)\n",
    "            Yte0 = pred.polynomial_prediction(s)\n",
    "            \n",
    "            y_val_np = y_val.values.reshape(Yte0.shape) if isinstance(y_val, pd.Series) else y_val\n",
    "\n",
    "            if (y_val_np.shape == Yte0.shape) : \n",
    "                score = mean_squared_error(Yte0, y_val_np)\n",
    "                scores.append(score)\n",
    "            else : \n",
    "                print(f\"Error size : y_val -> {y_val.shape} ,  Yte0 -> {Yte0.shape}\")\n",
    "                y_val_np = y_val.values.reshape(Yte0.shape) if isinstance(y_val, pd.Series) else y_val\n",
    "                score = mean_squared_error(Yte0, y_val_np)\n",
    "                scores.append(score)\n",
    "\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score < best_score:\n",
    "            best_score = avg_score\n",
    "            best_params = s\n",
    "\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be799b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_values = [1,2,3,4,5,6,7,8,9,10]  \n",
    "best_params, best_score = cross_validation(X0, y0, s_values)\n",
    "best_params1, best_score1 = cross_validation(X1, y1, s_values)\n",
    "best_params2 , best_score2 = cross_validation(X2, y2, s_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c0bd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "ker0 = kernels(X0)\n",
    "Kpol0 = ker0.polynomial_kernel(X0,best_params)\n",
    "Kpol0 = Kpol0 + 10**(-10) * np.eye(X0.shape[0])\n",
    "train = training_algo(Kpol0, 2*(y0 - 0.5))\n",
    "alpha = train.minimize_obj_fun(train.SVM, np.ones(Kpol0.shape[0]))\n",
    "pred0 = prediction(alpha.x, Xte0, ker0)\n",
    "Yte0 = pred0.polynomial_prediction(best_params)\n",
    "\n",
    "## Second dataset\n",
    "\n",
    "ker1 = kernels(X1)\n",
    "Kpol1 = ker1.polynomial_kernel(X1,best_params1)\n",
    "Kpol1 = Kpol1 + 10**(-10) * np.eye(X1.shape[0]) # to avoid \n",
    "train = training_algo(Kpol1, 2*(y1 - 0.5))\n",
    "alpha = train.minimize_obj_fun(train.SVM, np.ones(Kpol1.shape[0]))\n",
    "pred1 = prediction(alpha.x, Xte1, ker1)\n",
    "Yte1 = pred1.polynomial_prediction(best_params1)\n",
    "\n",
    "## Third Dataset\n",
    "\n",
    "ker2 = kernels(X2)\n",
    "Kpol2 = ker2.polynomial_kernel(X2,best_params2)\n",
    "Kpol2 = Kpol2 + 10**(-10) * np.eye(X2.shape[0])\n",
    "train = training_algo(Kpol2, 2*(y2 - 0.5))\n",
    "alpha = train.minimize_obj_fun(train.SVM, np.ones(Kpol2.shape[0]))\n",
    "pred2 = prediction(alpha.x, Xte2, ker2)\n",
    "Yte2 = pred2.polynomial_prediction(best_params2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e634e11",
   "metadata": {},
   "source": [
    "## Create a CSV for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2270f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_concatenee = []\n",
    "liste_concatenee.extend(Yte0)\n",
    "liste_concatenee.extend(Yte1)\n",
    "liste_concatenee.extend(Yte2)\n",
    "                    \n",
    "# Créer un DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Id': [int(x) for x in list(range(3000))],\n",
    "    'Bound': [int(x) for x in liste_concatenee] \n",
    "})\n",
    "df['Bound'] = df['Bound'].astype('int')\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "df.to_csv('Ypred_poly.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff559e0",
   "metadata": {},
   "source": [
    "# Prediction for polynomial using SVM2 with best parameters by SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "952f7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First dataset\n",
    "\n",
    "ker02 = kernels(X0)\n",
    "Kpol02 = ker02.polynomial_kernel(X0, best_params)\n",
    "Kpol02 = Kpol02 + 10**(-10) * np.eye(X0.shape[0])\n",
    "train02 = training_algo(Kpol02, 2*(y0 - 0.5))\n",
    "alpha02 = train02.minimize_obj_fun(train02.SVM2, np.ones(Kpol02.shape[0]))\n",
    "pred02 = prediction(alpha02.x, Xte0, ker02)\n",
    "Yte02 = pred02.polynomial_prediction(best_params)\n",
    "\n",
    "## Second dataset\n",
    "\n",
    "ker12 = kernels(X1)\n",
    "Kpol12 = ker12.polynomial_kernel(X1, best_params1)\n",
    "Kpol12 = Kpol12 + 10**(-10) * np.eye(X1.shape[0])  # To avoid numerical instability\n",
    "train12 = training_algo(Kpol12, 2*(y1 - 0.5))\n",
    "alpha12 = train12.minimize_obj_fun(train12.SVM2, np.ones(Kpol12.shape[0]))\n",
    "pred12 = prediction(alpha12.x, Xte1, ker12)\n",
    "Yte12 = pred12.polynomial_prediction(best_params1)\n",
    "\n",
    "## Third dataset\n",
    "\n",
    "ker22 = kernels(X2)\n",
    "Kpol22 = ker22.polynomial_kernel(X2, best_params2)\n",
    "Kpol22 = Kpol22 + 10**(-10) * np.eye(X2.shape[0])\n",
    "train22 = training_algo(Kpol22, 2*(y2 - 0.5))\n",
    "alpha22 = train22.minimize_obj_fun(train22.SVM2, np.ones(Kpol22.shape[0]))\n",
    "pred22 = prediction(alpha22.x, Xte2, ker22)\n",
    "Yte22 = pred22.polynomial_prediction(best_params2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d759f60",
   "metadata": {},
   "source": [
    "## Create a CSV for predictions (SVM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de501bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_concatenee = []\n",
    "liste_concatenee.extend(Yte02)\n",
    "liste_concatenee.extend(Yte12)\n",
    "liste_concatenee.extend(Yte22)\n",
    "                    \n",
    "# Créer un DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Id': [int(x) for x in list(range(3000))],\n",
    "    'Bound': [int(x) for x in liste_concatenee] \n",
    "})\n",
    "df['Bound'] = df['Bound'].astype('int')\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "df.to_csv('Ypred_poly2.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8065e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
